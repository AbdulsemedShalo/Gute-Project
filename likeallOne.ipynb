{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6T9V36eyuIjVI1TZ9NhnD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulsemedShalo/Gute-Project/blob/main/likeallOne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krhYTbd4Noe9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB #import gaussian naive bayes model\n",
        "from sklearn.tree import DecisionTreeClassifier #import Decision tree classifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics  #Import scikit-learn metrics module for accuracy calculation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Scatter and density plots\n",
        "def plotScatterMatrix(df, plotSize, textSize):\n",
        "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
        "    # Remove rows and columns that would lead to df being singular\n",
        "    df = df.dropna('columns')\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    columnNames = list(df)\n",
        "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
        "        columnNames = columnNames[:10]\n",
        "    df = df[columnNames]\n",
        "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
        "    corrs = df.corr().values\n",
        "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
        "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
        "    plt.suptitle('Scatter and Density Plot')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Distribution graphs (histogram/bar graph) of column data\n",
        "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
        "    nunique = df.nunique()\n",
        "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] \n",
        "\n",
        "    # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
        "    nRow, nCol = df.shape\n",
        "    columnNames = list(df)\n",
        "\n",
        "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
        "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
        "    for i in range(min(nCol, nGraphShown)):\n",
        "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
        "        columnDf = df.iloc[:, i]\n",
        "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
        "            valueCounts = columnDf.value_counts()\n",
        "            valueCounts.plot.bar()\n",
        "        else:\n",
        "            columnDf.hist()\n",
        "        plt.ylabel('counts')\n",
        "        plt.xticks(rotation = 90)\n",
        "        plt.title(f'{columnNames[i]} (column {i})')\n",
        "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    filename = df.dataframeName\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "# to check the number of rows we want to read for a preview\n",
        "nRowsRead = None\n",
        "\n",
        "# the path for a testing dataframe \n",
        "file_path_test=\"/content/tester.csv\"\n",
        "\n",
        "# the path for a training dataframe\n",
        "file_path_train=\"/content/trainer.csv\"\n",
        "\n",
        "\n",
        "df_trainer = pd.read_csv(file_path_train,nrows = nRowsRead)\n",
        "df_tester = pd.read_csv(file_path_test,nrows = nRowsRead)\n",
        "# describing both the test and train dataframes\n",
        "\n",
        "\n",
        "df_trainer.dataframeName = 'trainer.csv'\n",
        "df_tester.dataframeName =  'tester.csv'\n",
        "\n",
        "nRowsNum, nCol = df_trainer.shape\n",
        "nRowsNum2, nCol2 = df_tester.shape\n",
        "\n",
        "print(f'There are {nRowsNum} rows and {nCol} columns for training dataframe')\n",
        "print(f'There are {nRowsNum2} rows and {nCol2} columns for testing dataframe')\n",
        "#print(df_trainer.head(5))\n",
        "\n",
        "#plotPerColumnDistribution(df_trainer,10,5)\n",
        "#plotCorrelationMatrix(df_trainer,19)\n",
        "\n",
        "#plotCorrelationMatrix(df_tester,19)\n",
        "\n",
        "#plotScatterMatrix(df_trainer, 20, 10)\n",
        "\n",
        "#df_tester.head()\n",
        "\n",
        "\n",
        "# array(['BENIGN', 'DoS slowloris', 'DoS Hulk'], dtype=object)\n",
        "df_trainer['Label'].unique()\n",
        "df_tester['Label'].unique()\n",
        "\n",
        "# Encode the string classes to numeric to perform further processes.\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df_trainer['Label'] = label_encoder.fit_transform(df_trainer['Label'])\n",
        "df_tester['Label'] = label_encoder.fit_transform(df_tester['Label'])\n",
        "\n",
        "\n",
        "# split the data into train data and test data. As convention in machine learning, X_train,X_test are used for features and y_train,y_test are used for classes.\n",
        "X_train = df_trainer.drop('Label',axis=1)\n",
        "X_test = df_tester.drop('Label',axis=1)\n",
        "y_train = df_trainer['Label']\n",
        "y_test = df_tester['Label']\n",
        "\n",
        "# checking  train data\n",
        "X_train.head()\n",
        "y_train.head()\n",
        "\n",
        "\n",
        "# checking  test data\n",
        "X_test.head()\n",
        "y_test.head()\n",
        "\n",
        "\n",
        "# Accuracy test for Naive Baye's Algorithm\n",
        "\n",
        "# create gaussian naive bayes classifier\n",
        "gnb = GaussianNB()\n",
        "#Train the model using the training sets\n",
        "gnb.fit(X_train,y_train)\n",
        "#Predict the response for test dataset\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Naive Bayes's Accuracy : \",metrics.accuracy_score(y_test,gnb_pred))\n",
        "\n",
        "\n",
        "#DEscision Tree Accuracy \n",
        "clf = DecisionTreeClassifier()\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "#Predict the response for test dataset\n",
        "dt_pred = clf.predict(X_test)\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Decision Tree Classiffier Accuracy:\",metrics.accuracy_score(y_test, dt_pred))\n",
        "\n",
        "\n",
        "# Decision Tree with Max Depth 3\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "clf = clf.fit(X_train,y_train)\n",
        "dt_pred1 = clf.predict(X_test)\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Decision Tree with Max Depth Accuracy:\",metrics.accuracy_score(y_test, dt_pred1))\n",
        "\n",
        "\n",
        "#K-Nearest Neighbour Algorithm\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "model.fit(X_train, y_train)\n",
        "# Predict the attack\n",
        "predictions = model.predict(X_test)\n",
        "# Evaluate the model\n",
        "print('K-Nearest Neighbour Accuracy:', model.score(X_test, y_test))\n",
        "\n",
        "# Logistic Regression algorithm\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# Predict the labels of the test set\n",
        "y_pred = model.predict(X_test)\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Regression algorithm Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "# Support Vector Machine \n",
        "supp = SVC()\n",
        "supp = supp.fit(X_train,y_train)\n",
        "dt_pred1 = supp.predict(X_test)\n",
        "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test, dt_pred1))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}